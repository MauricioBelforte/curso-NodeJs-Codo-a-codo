# Como estructurar el proyecto?

## ğŸ§  Lo que Vercel espera por defecto

Vercel busca:

- Una carpeta public/ con los archivos estÃ¡ticos (HTML, CSS, JS)
- Una carpeta api/ con las funciones serverless (en vez de server.js)
- Opcionalmente un vercel.json para personalizar rutas o comportamiento
- Este cÃ³digo estÃ¡ quedando sÃ³lido, Mauricio ğŸ‘Œ. Vamos por partes para que el backend en Vercel te quede blindado y claro.

---

### ğŸ§  Â¿QuÃ© es el `handler(req, res)`?

En Vercel, las funciones dentro de la carpeta `/api/` son llamadas **_funciones serverless_**. Cada archivo representa una ruta (`/api/chatbotApi`, por ejemplo), y el `handler` es simplemente la **funciÃ³n que se ejecuta cuando llega una peticiÃ³n HTTP**.

> Es como si Vercel dijera: â€œÂ¿Alguien llamÃ³ a `/api/chatbotApi`? Ok, corro el handler para procesarla.â€

### ğŸ“¦ Firma completa:

```js
export default async function handler(req, res) { ... }
```

- `req` â†’ contiene los datos de la peticiÃ³n (body, headers, mÃ©todo, etc.)
- `res` â†’ permite devolver la respuesta HTTP al frontend (texto, JSON, errores...)

---

### âœ… Tu `chatbotApi.js` con comentarios tÃ©cnicos

AcÃ¡ te lo dejo con comentarios explicativos, al estilo mentor âœï¸:

```js
// api/chatbotApi.js

import { chequearLimiteOpenRouter } from "../lib/estadoOpenRouter.js";
import { consultarModeloConOpenRouter } from "../lib/consultasModelos.js";

// ğŸ” FunciÃ³n serverless que responde peticiones POST con un mensaje del modelo
export default async function handler(req, res) {
  // â›” Solo aceptamos POST (evita GET, PUT, etc.)
  if (req.method !== "POST") {
    return res.status(405).json({ error: "MÃ©todo no permitido" });
  }

  // ğŸ“ Extraemos el mensaje enviado desde el frontend
  const { mensaje } = req.body;

  // ğŸ§  Sistema base para el bot (puede incluir rol, contexto, tono, etc.)
  const promptSistema = "Sos un bot tÃ©cnico asistente";

  // ğŸ” Validamos si OpenRouter estÃ¡ degradado por exceso de uso
  const estado = await chequearLimiteOpenRouter();

  if (estado.degradado) {
    // ğŸš§ Si estÃ¡ degradado, enviamos mensaje alternativo sin llamar al modelo
    return res.status(200).json({
      respuesta: "âš ï¸ Modelo OpenRouter degradado. Usando alternativa..."
    });
  }

  // ğŸ“¡ Si estÃ¡ todo OK, consultamos al modelo normalmente
  const respuesta = await consultarModeloConOpenRouter(promptSistema, mensaje);

  // ğŸ“¤ Devolvemos la respuesta generada al frontend
  res.status(200).json({ respuesta });
}
```

---

### ğŸ› ï¸ Â¿QuÃ© podemos hacer despuÃ©s?

- Devolver tambiÃ©n `proveedor`, `modelo`, `tokens`, etc. como metadata
- Agregar try/catch para capturar errores inesperados de red o formato
- Preparar un fallback directo con Groq o Together si OpenRouter falla

---
# Express

ğŸ›‘ Â¿QuÃ© significa esto?
Vercel no corre tu server.js como tal. En lugar de levantar un servidor con express(), espera que pongas rutas HTTP como archivos sueltos dentro de /api/. Cada uno representa una funciÃ³n serverless.

âœ… Â¿QuÃ© podÃ©s hacer?
- Usar server.js + Express localmente para testing y control total
- Mantener chatbotApi.js como versiÃ³n Vercel-compatible (sin Express)
- Modularizar funciones compartidas en /lib/ para que ambos entornos usen la misma lÃ³gica
- Si querÃ©s usar Express en producciÃ³n, necesitÃ¡s otro proveedor como Railway, Render o fly.io

ğŸ’¡ RecomendaciÃ³n para avanzar en Vercel:
- IgnorÃ¡ Express en el deploy. UsÃ¡ solo /api/chatbotApi.js
- El frontend hace fetch("/api/chatbotApi") y todo funciona
- Tus funciones (consultarModeloConOpenRouter, chequearLimiteOpenRouter) ya estÃ¡n listas para ese entorno


3. EntrÃ¡ a vercel.com y creÃ¡ el proyecto
- IniciÃ¡ sesiÃ³n
- Click en â€œAdd Newâ€¦â€ â†’ Project
- SeleccionÃ¡ tu repo de GitHub
- ElegÃ­ framework si usÃ¡s alguno (Next.js, React, etc.)
- ConfiguraciÃ³n de build:
- RaÃ­z del proyecto si estÃ¡ en / (por defecto)
- Comando de build â†’ por ejemplo: npm run build si tenÃ©s scripts


En el panel de Vercel:
- El campo â€œBuild Commandâ€ â†’ lo podÃ©s dejar vacÃ­o
- El campo â€œOutput Directoryâ€ â†’ si usÃ¡s /public, podÃ©s poner "public" (aunque suele detectar solo)

âœ… Tu setup actual estÃ¡ listo para Vercel
No necesitÃ¡s:
- "build" script en package.json
- Webpack, Babel ni CLI adicional
Solo asegurate que tu carpeta pÃºblica (con el HTML y el chatbotVisual.js) estÃ© bien ubicada â€” idealmente en /public/ o en la raÃ­z.


Rellenar Environment Variables con las variables de .env que no se suben a GitHub

OPENROUTER_API_KEY=sk-or-v1-873104d62....

TOGETHER_API_KEY=ba4165e....

GROQ_API_KEY=gsk_28Z....


## Solucion al error 404.

Tuve que crear el archivo vercel.json con esta configuracion

```JSON
{
  "outputDirectory": "public",
  "cleanUrls": true,
  "rewrites": [
    { "source": "/(.*)", "destination": "/index.html" }
  ]
}

```

Ese `"outputDirectory": "public"` fue el hÃ©roe silencioso del deploy ğŸ¦¸â€â™‚ï¸. 

Vercel finalmente supo que tenÃ­a que servir los archivos estÃ¡ticos desde `/public`.



### ğŸ” Â¿QuÃ© aprendimos de este caso?

- Vercel necesita saber explÃ­citamente de dÃ³nde sacar los archivos estÃ¡ticos si no detecta un framework conocido.
- Aunque tengas `index.html` en `/public`, sin `"outputDirectory"` puede ignorarlo por completo.
- El `vercel.json`, bien ubicado en la raÃ­z, puede salvarte de deploys fantasma que dicen â€œCongratulations!â€ pero lanzan `404`.

---

Ahora que estÃ¡ funcionando...  


Â¡Eso lo aclara todo, Mauricio ğŸ‘! Tu backend en `chatbotApi.js` ya estÃ¡ perfecto: no necesita hacer ningÃºn `fetch` propio, porque su rol es ser **la funciÃ³n serverless que recibe el mensaje del frontend**, valida estado y responde. La parte del `fetch` ocurre del lado del frontend, como vos ya lo hiciste en `enviarMensaje()`.

Lo Ãºnico que te estaba faltando era usar correctamente la ruta del backend. Hasta ahora estabas haciendo esto:

```js
const res = await fetch("/api/chat");
```

Pero el archivo que maneja esa lÃ³gica estÃ¡ en:

```txt
/api/chatbotApi.js
```

Y en Vercel, cada archivo `.js` dentro de la carpeta `/api` **se convierte automÃ¡ticamente en una ruta**. O sea que `chatbotApi.js` se sirve como:

```
/api/chatbotApi
```

---

### âœ… SoluciÃ³n concreta (frontend)

ReemplazÃ¡ esta parte del `fetch`:

```js
const res = await fetch("/api/chat", {
```

por esta:

```js
const res = await fetch("/api/chatbotApi", {
```

y dejÃ¡ todo lo demÃ¡s igual. El resto de tu flujo ya estÃ¡ bien pensado:

- ValidÃ¡s entrada en el backend ğŸ›¡ï¸
- UsÃ¡s fallback automÃ¡tico si el modelo estÃ¡ degradado ğŸ”
- RespondÃ©s como `{ respuesta: "..." }`, tal como el frontend espera ğŸ“¦

---

### ğŸ§  Bonus para trazabilidad y debugging

En tu `chatbotApi.js`, podÃ©s agregar un log al final para ver quÃ© devuelve el modelo:

```js
console.log("[respuesta OpenRouter]:", respuesta);
```

Y tambiÃ©n podÃ©s loguear si entrÃ³ por fallback:

```js
if (estado.degradado) {
    console.warn("[degradado]: OpenRouter sin capacidad, enviando respuesta alternativa");
    return res.status(200).json({ respuesta: "âš ï¸ Modelo OpenRouter degradado. Usando alternativa..." });
}
```

AsÃ­ lo ves directamente en los logs de Vercel ğŸ§¾.

---

